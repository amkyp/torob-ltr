{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown\n",
    "\n",
    "!pip install -q hazm\n",
    "!pip install -q parsivar\n",
    "\n",
    "!pip install -q datasets  --no-cache-dir\n",
    "!pip install -q transformers  --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2631621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q \"datasets==2.10.1\" # previously 2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "datasets.__version__ # '2.9.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import sqlite3\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import hazm\n",
    "from parsivar import Normalizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    load_dataset,\n",
    "    load_metric,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8d21b",
   "metadata": {},
   "source": [
    "## Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a194b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormalizer:\n",
    "    def __init__(self):\n",
    "        self.parsivar_normalizer = Normalizer(\n",
    "            statistical_space_correction=True,\n",
    "            half_space_char=\" \",\n",
    "            pinglish_conversion_needed=True,\n",
    "        )\n",
    "        self.hazm_normalizer = hazm.Normalizer(\n",
    "            remove_extra_spaces=True,\n",
    "            persian_numbers=True,\n",
    "            persian_style=True,\n",
    "            punctuation_spacing=False,\n",
    "            remove_diacritics=True,\n",
    "            affix_spacing=False,\n",
    "            token_based=True,\n",
    "        )\n",
    "\n",
    "    def normalize(self, txt):\n",
    "        return self.hazm_normalizer.normalize(\n",
    "            self.parsivar_normalizer.normalize(\n",
    "                txt.replace(\"\\n\", \" \").replace(\"\\u200c\", \" \").lower().strip()\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb566e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MyNormalizer()\n",
    "normalizer.normalize(\"34.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34103aa6",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71cd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonFileIterator:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.f = open(path, \"r\")\n",
    "        self.i = 0\n",
    "        self.length = self.counter_lines()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        line = self.f.readline()\n",
    "        if not line:\n",
    "            # End of file\n",
    "            self.f.close()\n",
    "            raise StopIteration\n",
    "        self.i += 1\n",
    "        return json.loads(line)\n",
    "\n",
    "    def counter_lines(self):\n",
    "        with open(self.path, \"r\") as f1:\n",
    "            return sum(1 for _ in f1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee7475",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = JsonFileIterator(\"./data/test-offline-data_v1.jsonl\")\n",
    "test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2399126",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = joblib.load(f\"./retrive/test_query/test_spell_checked.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b226fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    word = row['raw_query']\n",
    "    if word in correction:\n",
    "        corrected_word = correction[word]\n",
    "        test_df.at[i, 'raw_query'] = corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8739d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test-offline-data_v1-torob_v4_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7a533",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data = JsonFileIterator(\"./data/torob-search-data_v1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92924957",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df = pd.DataFrame(search_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21da1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = joblib.load(f\"spell_check-corrections.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72def13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correction) #75895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"دوچرخ\" in correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(search_df.iterrows(), total=len(search_df)):\n",
    "    word = row['raw_query']\n",
    "    if word in correction:\n",
    "        corrected_word = correction[word]\n",
    "        search_df.at[i, 'raw_query'] = corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df[search_df[\"raw_query\"] == \"دوچرخه\"].shape # (37035, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df.to_csv('torob_v4_2-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63544139",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MyNormalizer()\n",
    "queries = dict()\n",
    "for search in tqdm(search_df.to_dict('records')):\n",
    "    query = search[\"raw_query\"]\n",
    "    normalized_query = normalizer.normalize(query)\n",
    "    if normalized_query not in queries:\n",
    "        queries[normalized_query] = 1\n",
    "    else:\n",
    "        queries[normalized_query] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ac986",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c94be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d454b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df['raw_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a716787",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_searches = defaultdict(\n",
    "    lambda: dict(\n",
    "        results = Counter(),\n",
    "        clicks = Counter(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ead737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aggregating searches based on raw query...\")\n",
    "\n",
    "for i, search in tqdm_notebook(search_df.iterrows(), total=len(search_df)):\n",
    "    normalized_query     raw_query = search[\"raw_query\"]\n",
    "= normalizer.normalize(raw_query)\n",
    "\n",
    "    if queries[normalized_query] >= 10:\n",
    "        results = search[\"result\"][: np.max(search[\"clicked_rank\"]) + 8]\n",
    "        clicked_results = search[\"clicked_result\"]\n",
    "        agg_searches[normalized_query][\"results\"].update(results)\n",
    "        agg_searches[normalized_query][\"clicks\"].update(clicked_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_searches) # 10435 # 33254"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac22a2f",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "with open('stop-words.txt', encoding='utf-8' ) as f:\n",
    "    for line in f:\n",
    "        stopwords.append(normalizer.normalize(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_words(titles_list, index_high_len):\n",
    "    highest_len_title_words = titles_list[index_high_len].split()\n",
    "    total_new_words = []\n",
    "    for i in range(1, len(titles_list)):\n",
    "        if i != index_high_len:\n",
    "            words = titles_list[i].split()\n",
    "            new_words = [word for word in words if word not in highest_len_title_words]\n",
    "            new_words = [word for word in new_words if word not in stopwords]\n",
    "            total_new_words += new_words\n",
    "    return list(set(total_new_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecc6b6",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25155c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_s = list(agg_searches.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/torob_list_search', 'wb') as fp:\n",
    "#     pickle.dump(agg_s, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d167ed",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f107ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_s[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca37f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_searches[agg_s[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ecfd5",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info = JsonFileIterator(\"./data/products-info_v1.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490aa3c9",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_lines(path, n_lines=None):\n",
    "    \"\"\"Creates a generator which reads and returns lines of\n",
    "    a json lines file, one line at a time, each as a dictionary.\n",
    "\n",
    "    This could be used as a memory-efficient alternative of `pandas.read_json`\n",
    "    for reading a json lines file.\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if n_lines == i:\n",
    "                break\n",
    "            yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01700654",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = pd.DataFrame(read_json_lines('./data/products-info_v1.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = product.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product.category_name.unique()) # 3569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "product.loc[1867826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0847cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "product.loc[1867826][\"titles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6642d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "product.loc[1867826].min_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584abca",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd889a79",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset_v4_2.txt\", \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    wrtiter = csv.writer(csvfile)\n",
    "    wrtiter.writerow(\n",
    "        [\n",
    "            \"query\",\n",
    "            \"product_id\",\n",
    "            \"p_des\",\n",
    "            \"product_title\",\n",
    "            \"category_name\",\n",
    "            \"min_num_shops\",\n",
    "            \"max_num_shops\",\n",
    "            \"avg_num_shops\",\n",
    "            \"min_price\",\n",
    "            \"max_price\",\n",
    "            \"avg_price\",\n",
    "            \"mean_min_prices\",\n",
    "            \"mean_max_prices\",\n",
    "            \"mean_avg_prices\",\n",
    "            \"std_min_prices\",\n",
    "            \"std_max_prices\",\n",
    "            \"std_avg_prices\",\n",
    "            \"num_query\",\n",
    "            \"impression\",\n",
    "            \"candidate_score1\",\n",
    "            \"candidate_score2\",\n",
    "            \"clicks\",\n",
    "            \"max_clicks\",\n",
    "            \"len_results\",\n",
    "            \"impressions\",\n",
    "            \"ctr\",\n",
    "            \"max_shop_processed\",\n",
    "            \"popularity\",\n",
    "        ]\n",
    "    )\n",
    "    # conn = sqlite3.connect(\"my_database.db\")\n",
    "    # c = conn.cursor()\n",
    "    \n",
    "    data_list = [] \n",
    "    \n",
    "    for query in tqdm_notebook(agg_s):\n",
    "        \n",
    "#         print(query)\n",
    "        results = agg_searches[query]\n",
    "\n",
    "        # print(results) #\n",
    "\n",
    "        min_prices = []\n",
    "        max_prices = []\n",
    "        avg_prices = []\n",
    "\n",
    "        for product_id, res_clicks in results[\"results\"].most_common(90):\n",
    "            if product_id != None:\n",
    "\n",
    "                result_product = product.loc[product_id]\n",
    "\n",
    "                # c.execute(\"SELECT * FROM products WHERE id = ?\", (product_id,))\n",
    "                # result_product = c.fetchone()\n",
    "\n",
    "                if result_product[2] != None:\n",
    "                    if result_product[2] != None:\n",
    "                        min_prices.append(result_product[2])\n",
    "                    if result_product[3] != None:\n",
    "                        max_prices.append(result_product[3])\n",
    "                    if result_product[4] != None:\n",
    "                        avg_prices.append(result_product[4])\n",
    "\n",
    "            mean_min_prices = np.mean(min_prices)\n",
    "            mean_max_prices = np.mean(max_prices)\n",
    "            mean_avg_prices = np.mean(avg_prices)\n",
    "\n",
    "            std_min_prices = np.std(min_prices)\n",
    "            std_max_prices = np.std(max_prices)\n",
    "            std_avg_prices = np.std(avg_prices)\n",
    "\n",
    "        for product_id, res_clicks in results[\"results\"].most_common(90):\n",
    "            if product_id != None:\n",
    "#                 print(product_id)\n",
    "                # c.execute(\"SELECT * FROM products WHERE id = ?\", (product_id,))\n",
    "                # result_product = c.fetchone()\n",
    "\n",
    "#                 print(res_clicks) # impression\n",
    "\n",
    "                result_product = product.loc[product_id]\n",
    "\n",
    "                ##################################################\n",
    "                # print(result_product)\n",
    "                ##################################################\n",
    "\n",
    "                category_name = result_product[0]\n",
    "                min_price = result_product[2]\n",
    "                max_price = result_product[3]\n",
    "                avg_price = result_product[4]\n",
    "\n",
    "                titles_list_product = product.loc[product_id][\"titles\"]\n",
    "#                 print(titles_list_product)\n",
    "\n",
    "                # titles_list_product = json.loads(result_product[2])\n",
    "\n",
    "                if len(titles_list_product) > 0:\n",
    "                    min_num_shops = result_product[5]\n",
    "                    max_num_shops = result_product[6]\n",
    "                    avg_num_shops = result_product[7]\n",
    "                    highest_len_product = max(titles_list_product, key=len)\n",
    "                    index_highest_len_product = titles_list_product.index(\n",
    "                        highest_len_product\n",
    "                    )\n",
    "                    product_title_new_words = find_new_words(\n",
    "                        titles_list_product, index_highest_len_product\n",
    "                    )\n",
    "\n",
    "                    # highest length product title\n",
    "                    product_title = highest_len_product\n",
    "\n",
    "                    p_des = \" \".join(\n",
    "                        [highest_len_product, \" \".join(product_title_new_words)]\n",
    "                    ).replace(\"\\u200c\", \" \")\n",
    "\n",
    "                    clicks = results[\"clicks\"].get(product_id, 0)\n",
    "                    max_clicks = np.max(list(results[\"clicks\"].values()))\n",
    "\n",
    "#                     print(\"clicks: \", clicks, \"max_clicks: \", max_clicks)\n",
    "#                     print(\"clicks by max clicks:\", clicks/max_clicks)\n",
    "\n",
    "                    ##### score \n",
    "                    candidate_score = results[\"clicks\"].get(product_id, 0)\n",
    "                    candidate_score1 = np.log2(candidate_score + 1)\n",
    "                    candidate_score2 = np.log2(candidate_score + 1) / np.log2(\n",
    "                        max_clicks + 1\n",
    "                    )\n",
    "\n",
    "                    # clicks, impressions, ctr, ctr_laplace_normalized, \n",
    "\n",
    "                    clicks = results[\"clicks\"].get(product_id, 0)\n",
    "# \n",
    "#                     print(\"=======================s of impre=======================\")\n",
    "#                     print(results[\"results\"].get(product_id, 0))\n",
    "#                     print(\"=======================e of impre=======================\")\n",
    "# \n",
    "                    impressions = results[\"results\"].get(product_id, 0)\n",
    "\n",
    "                    ctr = clicks / impressions\n",
    "\n",
    "#                     print(max_clicks)\n",
    "#                     ctr_laplace_normalized = (clicks + 1) / (impressions + len(results[\"results\"]))\n",
    "\n",
    "                    len_result =  len(results[\"results\"])\n",
    " \n",
    "                    # click_per_maxclick = clicks + 1 / max_clicks + 1\n",
    "                    # ctr_normalized_multiplied_clicks_normalized = ctr_laplace_normalized * click_per_maxclick\n",
    "\n",
    "                    max_shop_processed = normalizer.normalize(str(int(np.log2(int(max_num_shops) + 1))))\n",
    "                    popularity = \"popularity is \" + max_shop_processed\n",
    "\n",
    "                    wrtiter.writerow(\n",
    "                        [\n",
    "                            query,\n",
    "                            product_id,\n",
    "                            p_des,\n",
    "                            product_title,\n",
    "                            category_name,\n",
    "                            min_num_shops,\n",
    "                            max_num_shops,\n",
    "                            avg_num_shops,\n",
    "                            min_price,\n",
    "                            max_price,\n",
    "                            avg_price,\n",
    "                            mean_min_prices,\n",
    "                            mean_max_prices,\n",
    "                            mean_avg_prices,\n",
    "                            std_min_prices,\n",
    "                            std_max_prices,\n",
    "                            std_avg_prices,\n",
    "                            queries[query],\n",
    "                            res_clicks, # impression\n",
    "                            candidate_score1,\n",
    "                            candidate_score2,\n",
    "                            clicks,\n",
    "                            max_clicks,\n",
    "                            len_result, # number of product for intended query\n",
    "                            impressions, # impression\n",
    "                            ctr, # not normalized with laplacian\n",
    "                            max_shop_processed,\n",
    "                            popularity,\n",
    "                        ]\n",
    "                    )\n",
    "    # conn.close()\n",
    "\n",
    "df = pd.read_csv(\"dataset_v4_2.txt\", sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a0e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d943b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3db305",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(df, \"dataset_v4_2.pkl\") # len is 603637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = joblib.load(\"dataset_v4_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_product = product.loc[7861059]\n",
    "result_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1905bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = agg_searches[\"ساعت هوشمند\"]\n",
    "agg_searches[\"ساعت هوشمند\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(results[\"results\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = df.copy(deep=True)\n",
    "# df.iloc[226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16befaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = copy.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08143fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cf23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fill = ['min_price', 'max_price', 'avg_price', 'mean_min_prices', 'mean_max_prices', 'mean_avg_prices', 'std_min_prices', 'std_max_prices', 'std_avg_prices']\n",
    "for col in cols_to_fill:\n",
    "    temp_df[col] = temp_df[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00218df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54181745",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[\"clicks_by_max_clicks\"] = (temp_df['clicks'] + 1) / (temp_df['max_clicks'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613cce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[\"ctr_normalized_by_click_normalized\"] = ((temp_df['clicks'] + 1) / (temp_df['impressions'] + temp_df['len_results'])) * (temp_df['clicks_by_max_clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae700d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babbb2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[\"ctr_normalized\"] = ((temp_df['clicks'] + 1) / (temp_df['impressions'] + temp_df['len_results']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6120ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = temp_df.set_index(\"product_id\").groupby(\"query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.get_group(\"دوچرخه\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = temp_df.groupby([\"product_id\", \"query\"]).agg({\"ctr_normalized\": \"max\"})\n",
    "\n",
    "# grouped = grouped.reset_index()\n",
    "\n",
    "# temp_df = temp_df.merge(grouped, on=[\"product_id\", \"query\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc15599",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = temp_df.groupby(\"query\")\n",
    "max_ctr = grouped[\"ctr_normalized\"].transform(np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2395695",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[\"max_ctr\"] = max_ctr\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['ctr_by_max_ctr'] = temp_df['ctr_normalized'] / temp_df['max_ctr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22371f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f345e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['graded_ctr_norm'] = temp_df['ctr_by_max_ctr'] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976737a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# temp_df.iloc[0]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['ctr_norm_by_max_click_norm'] = temp_df['graded_ctr_norm'] * temp_df['clicks_by_max_clicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ctr_laplace_normalized = (clicks + 1) / (impressions + len(results[\"results\"]))\n",
    "# df[\"ctr_laplace_normalized_2\"] = (df[\"clicks\"] + 1) / (df[\"max_clicks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e40529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"click_per_maxclick\"] = df[\"clicks\"] / df[\"max_clicks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d52869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"clicks\"]==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5c941",
   "metadata": {},
   "source": [
    "# len(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25188fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show query with minimum number of products\n",
    "temp_df.groupby(\"query\").size().sort_values(ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show \"moripods\" products\n",
    "# df[df[\"query\"] == \"moripods\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea98f39",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb11771",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model = \"HooshvareLab/bert-fa-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(c_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(record):\n",
    "    query = record[\"query\"]\n",
    "    p_des = normalizer.normalize(record[\"p_des\"])\n",
    "    category = record[\"category_name\"]\n",
    "    popularity = record[\"popularity\"]\n",
    "    avg_price = record[\"avg_price\"]\n",
    "    std_avg_prices = record[\"std_avg_prices\"]\n",
    "    mean_avg_prices = record[\"mean_avg_prices\"]\n",
    "\n",
    "    if (avg_price is not None) and (not np.isnan(avg_price)) and (std_avg_prices != 0):\n",
    "        price_level = \"price is \" + normalizer.normalize(\n",
    "            str(int((((avg_price - mean_avg_prices) / std_avg_prices) + 2) * 5))\n",
    "        )\n",
    "    else:\n",
    "        price_level = \"price is none\"\n",
    "        \n",
    "    encoded_text = tokenizer(\n",
    "        query,\n",
    "        category + \" \" + popularity + \" \" + \" \" + price_level + \" \" + p_des,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    label = record[\"ctr_norm_by_max_click_norm\"]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": encoded_text[\"input_ids\"],\n",
    "        \"attention_mask\": encoded_text[\"attention_mask\"],\n",
    "        \"token_type_ids\": encoded_text[\"token_type_ids\"],\n",
    "        \"label\": label,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = temp_df.copy(deep=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d96598",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df) # 603637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef599d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df.sample(frac=0.9, random_state=42)\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "train_dataset.shape, test_dataset.shape # ((543273, 35), (60364, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d932610",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "test_dataset = Dataset.from_pandas(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0384c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79725d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(preprocess, remove_columns=train_dataset.column_names)\n",
    "test_dataset = test_dataset.map(preprocess, remove_columns=test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "train_dataset.save_to_disk(\"train_dataset_v4_2\")\n",
    "test_dataset.save_to_disk(\"test_dataset_v4_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
