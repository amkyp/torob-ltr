{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597baf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import sqlite3\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import hazm\n",
    "from parsivar import Normalizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    load_dataset,\n",
    "    load_metric,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99dd830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormalizer:\n",
    "    def __init__(self):\n",
    "        self.parsivar_normalizer = Normalizer(\n",
    "            statistical_space_correction=True,\n",
    "            half_space_char=\" \",\n",
    "            pinglish_conversion_needed=True,\n",
    "        )\n",
    "        self.hazm_normalizer = hazm.Normalizer(\n",
    "            remove_extra_spaces=True,\n",
    "            persian_numbers=True,\n",
    "            persian_style=True,\n",
    "            punctuation_spacing=False,\n",
    "            remove_diacritics=True,\n",
    "            affix_spacing=False,\n",
    "            token_based=True,\n",
    "        )\n",
    "\n",
    "    def normilize(self, txt):\n",
    "        return self.hazm_normalizer.normalize(\n",
    "            self.parsivar_normalizer.normalize(\n",
    "                txt.replace(\"\\n\", \" \").replace(\"\\u200c\", \" \").lower().strip()\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90b7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonFileIterator:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.f = open(path, 'r')\n",
    "        self.i = 0\n",
    "        self.length = self.counter_lines()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        line = self.f.readline()\n",
    "        if not line:\n",
    "            # End of file\n",
    "            self.f.close()\n",
    "            raise StopIteration\n",
    "        self.i += 1\n",
    "        return json.loads(line)\n",
    "        \n",
    "    def counter_lines(self):\n",
    "        with open(self.path, 'r') as f1:\n",
    "            return sum(1 for _ in f1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return  self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c14f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_words(titles_list , index_high_len):\n",
    "    highest_len_title_words = titles_list[index_high_len].split()\n",
    "    total_new_words = []\n",
    "    for i in range(1, len(titles_list)):\n",
    "        if i != index_high_len:\n",
    "            words = titles_list[i].split()\n",
    "            new_words = [word for word in words if word not in highest_len_title_words]\n",
    "            new_words = [word for word in new_words if word not in stopwords]\n",
    "            total_new_words += new_words\n",
    "    return list(set(total_new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca533cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "normalizer = MyNormalizer()\n",
    "with open('stop-words.txt', encoding='utf-8' ) as f:\n",
    "    for line in f:\n",
    "        stopwords.append(normalizer.normilize(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c80b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f0767a882a432181dfeb90a26568df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = JsonFileIterator(\"./test-offline-data_v1.jsonl\")\n",
    "with open('test_dataset_v4.txt', 'w', encoding=\"utf-8\", newline='') as csvfile:\n",
    "    wrtiter = csv.writer(csvfile)\n",
    "    wrtiter.writerow([\"row_number\" , \"query\",\n",
    "                                  \"product_id\",\n",
    "                                  \"p_des\",\n",
    "                                  \"category_name\",\n",
    "                                  \"min_num_shops\",\n",
    "                                  \"max_num_shops\",\n",
    "                                  \"avg_num_shops\",\n",
    "                                  \"min_price\",\n",
    "                                  \"max_price\",\n",
    "                                  \"avg_price\",\n",
    "                                  \"mean_min_prices\",\n",
    "                                  \"mean_max_prices\",\n",
    "                                  \"mean_avg_prices\",\n",
    "                                  \"std_min_prices\",\n",
    "                                  \"std_max_prices\",\n",
    "                                  \"std_avg_prices\"])\n",
    "    conn = sqlite3.connect('my_database.db')\n",
    "    c = conn.cursor()\n",
    "    data_list = []\n",
    "    for idx , test_rec in enumerate(tqdm_notebook(test_data)):\n",
    "        query = test_rec[\"raw_query\"]\n",
    "        results = test_rec[\"result_not_ranked\"]\n",
    "        min_prices = []\n",
    "        max_prices = []\n",
    "        avg_prices = []\n",
    "        \n",
    "        for product_id in results:\n",
    "            if product_id != None:\n",
    "                c.execute('SELECT * FROM products WHERE id = ?', (product_id,))\n",
    "                result_product = c.fetchone()\n",
    "                if result_product!= None:\n",
    "                    if result_product[3] != None:\n",
    "                        min_prices.append(result_product[3])\n",
    "                    if result_product[4] != None:\n",
    "                        max_prices.append(result_product[4])\n",
    "                    if result_product[5] != None:\n",
    "                        avg_prices.append(result_product[5])\n",
    "            mean_min_prices = np.mean(min_prices)\n",
    "            mean_max_prices = np.mean(max_prices)\n",
    "            mean_avg_prices = np.mean(avg_prices)\n",
    "\n",
    "            std_min_prices = np.std(min_prices)\n",
    "            std_max_prices = np.std(max_prices)\n",
    "            std_avg_prices = np.std(avg_prices)\n",
    "\n",
    "        for product_id in results:\n",
    "            if product_id != None:\n",
    "                c.execute('SELECT * FROM products WHERE id = ?', (product_id,))\n",
    "                result_product = c.fetchone()\n",
    "                category_name = result_product[1]\n",
    "                min_price = result_product[3]\n",
    "                max_price = result_product[4]\n",
    "                avg_price = result_product[5]\n",
    "                titles_list_product = json.loads(result_product[2])\n",
    "                if len(titles_list_product)>0 :\n",
    "                    min_num_shops = result_product[6]\n",
    "                    max_num_shops = result_product[7]\n",
    "                    avg_num_shops = result_product[8]\n",
    "                    highest_len_product = max(titles_list_product, key=len)\n",
    "                    index_highest_len_product = titles_list_product.index(highest_len_product)\n",
    "                    product_title_new_words = find_new_words(titles_list_product,index_highest_len_product)\n",
    "                    p_des = \" \".join([highest_len_product , \" \".join(product_title_new_words)]).replace(\"\\u200c\",\" \")\n",
    "                    wrtiter.writerow( [idx , normalizer.normilize(query),\n",
    "                                      product_id,\n",
    "                                      p_des,\n",
    "                                      category_name,\n",
    "                                      min_num_shops,\n",
    "                                      max_num_shops,\n",
    "                                      avg_num_shops,\n",
    "                                      min_price,\n",
    "                                      max_price,\n",
    "                                      avg_price,\n",
    "                                      mean_min_prices,\n",
    "                                      mean_max_prices,\n",
    "                                      mean_avg_prices,\n",
    "                                      std_min_prices,\n",
    "                                      std_max_prices,\n",
    "                                      std_avg_prices,])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5d364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
