{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n",
        "\n",
        "    <!-- https://github.com/pyg-team/pyg-lib -->\n",
        "\n",
        "    conda install pyg -c pyg\n",
        "\n",
        "    pip install -Uq sentence-transformers\n",
        "    \n",
        "    pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\n",
        "\n",
        "    pip install ogb\n",
        "\n",
        "    conda install tqdm jupyter ipywidgets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "11.7\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JqqYkw2DMJrg"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# from torch_geometric.data import Data\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hjwgSAcdMMOP"
      },
      "outputs": [],
      "source": [
        "if os.path.exists('LaBSE'):\n",
        "    model = SentenceTransformer('LaBSE')\n",
        "else:\n",
        "    model = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "    model.save('LaBSE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def read_json_lines(path, n_lines=None):\n",
        "    \"\"\"Creates a generator which reads and returns lines of\n",
        "    a json lines file, one line at a time, each as a dictionary.\n",
        "    \n",
        "    This could be used as a memory-efficient alternative of `pandas.read_json`\n",
        "    for reading a json lines file.\n",
        "    \"\"\"\n",
        "    with open(path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if n_lines == i:\n",
        "                break\n",
        "            yield json.loads(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIdbObOUL8Uu",
        "outputId": "3fd58f20-807a-4257-cf72-6ea03cd8754c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 768)\n"
          ]
        }
      ],
      "source": [
        "queries_embeddings = model.encode(raw_query)\n",
        "print(queries_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYXSghdKN20h"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppX_JPtoNoDD"
      },
      "source": [
        "  Torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xcY7Rk3K1dMx"
      },
      "outputs": [],
      "source": [
        "# !pip install -U torch==1.8.0 torchtext==0.9.0\n",
        "\n",
        "# # Reload environment\n",
        "# exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rTkMnhWL6J3W"
      },
      "outputs": [],
      "source": [
        "# from torchtext.legacy import data, datasetes\n",
        "\n",
        "# filename = 'glove.6B.zip'\n",
        "# url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "# torchtext.utils.download_from_url(url, filename)\n",
        "\n",
        "# !unzip glove.6B.zip -d .vector_cache\n",
        "\n",
        "# import torchtext\n",
        "# from torchtext.legacy import data, datasetes\n",
        "\n",
        "# def preprocess_queries(raw_query):\n",
        "#     text = data.Field(sequential=True)\n",
        "#     text.build_vocab([data.Example.fromlist([i], [(\"text\", text)]) for i in raw_query], \n",
        "#                      vectors=torchtext.vocab.Vectors(\"glove.6B.50d.txt\"))\n",
        "#     queries = [text.process([i]) for i in raw_query]\n",
        "#     queries = torch.cat(queries).squeeze(1)\n",
        "#     return queries\n",
        "\n",
        "# raw_query = [\"search for laptops\", \"best camera under 500\", \"phone under 200\"]\n",
        "# queries = preprocess_queries(raw_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aul7QqqN54i"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLC4Wh3KN9eo"
      },
      "source": [
        "  Convert to Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "jTYXIBYDKBxg",
        "outputId": "ff0c3afc-e0fe-4705-a77a-26a8c07f7716"
      },
      "outputs": [],
      "source": [
        "# def convert_to_graph(raw_query, product_info, query_result, clicked_rank):\n",
        "#     edge_index = []\n",
        "#     x = []\n",
        "#     edge_attr = []\n",
        "#     query_index = {}\n",
        "#     product_index = {}\n",
        "\n",
        "#     for i, q in enumerate(raw_query):\n",
        "#         query_index[q] = i\n",
        "#         x.append(q)\n",
        "\n",
        "#     for j, p in enumerate(product_info):\n",
        "#         product_index[p[0]] = j + len(raw_query)\n",
        "#         x.append(p)\n",
        "\n",
        "#     for i, (q, result) in enumerate(query_result):\n",
        "#         for r in result:\n",
        "#             edge_index.append([query_index[q], product_index[r]])\n",
        "#             edge_attr.append([clicked_rank[i][result.index(r)]])\n",
        "\n",
        "#     edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "#     edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "#     x = torch.tensor(x, dtype=torch.float)\n",
        "\n",
        "#     return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "\n",
        "# product_info = [[1, \"laptop\", 500, 800, 650, 5, 10, 7],\n",
        "#                 [2, \"camera\", 400, 450, 425, 3, 5, 4],\n",
        "#                 [3, \"phone\", 150, 199, 175, 2, 3, 2.5]]\n",
        "# query_result = [(\"search for laptops\", [1]),\n",
        "#                 (\"best camera under 500\", [2]),\n",
        "#                 (\"phone under 200\", [3])]\n",
        "# clicked_rank = [[1], [1], [1]]\n",
        "\n",
        "# graph_data = convert_to_graph(queries_embeddings, product_info, query_result, clicked_rank)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Load the query data into a pandas dataframe\n",
        "# query_df = pd.DataFrame({\n",
        "#     'raw_query': [\n",
        "#         'لوستر سقفی برنز',\n",
        "#         'قیمت هلیکوپتر',\n",
        "#         'ساعت هوشمند'\n",
        "#     ],\n",
        "#     'result': [\n",
        "#         [7151290, 6462477, 7385791, 8451497, None, 269...],\n",
        "#         [363737, 3147253, 8720128, 9796388, 1420685, 5...],\n",
        "#         [2459592, 9391819, 4229448, 7824893, 1670767, ...]\n",
        "#     ],\n",
        "#     'clicked_result': [\n",
        "#         [9457219],\n",
        "#         [3147253, 7135387],\n",
        "#         [900897, 2931230, 31302]\n",
        "#     ],\n",
        "#     'clicked_rank': [\n",
        "#         [16],\n",
        "#         [1, 7],\n",
        "#         [7, 25, 52]\n",
        "#     ],\n",
        "#     'timestamp': [\n",
        "#         '2022-07-24T09:21:58.752000+00:00',\n",
        "#         '2022-07-24T07:32:12.261000+00:00',\n",
        "#         '2022-07-24T02:51:35.643000+00:00'\n",
        "#     ]\n",
        "# })\n",
        "\n",
        "# # Load the product data into a pandas dataframe\n",
        "# product_df = pd.DataFrame({\n",
        "#     'id': [\n",
        "#         1867826,\n",
        "#         419611,\n",
        "#         288575,\n",
        "#         4614227,\n",
        "#         4108604\n",
        "#     ],\n",
        "#     'category_name': [\n",
        "#         'میکروسکوپ',\n",
        "#         'ماشین اسباب بازی',\n",
        "#         'کتاب و مجلات',\n",
        "#         'لپ تاپ و نوت بوک',\n",
        "#         'کتاب و مجلات'\n",
        "#     ],\n",
        "#     'titles': [\n",
        "#         ['میکروسکوپ اپتیکی سلسترون مدل 44121 CGL'],\n",
        "#         ['ماشین بازی فورد موستانگ مایستو مدل 2015 Ford ...'],\n",
        "#         ['کتاب راهنمای کاربردی عیب یابی و تعمیر موتور س...'],\n",
        "#         ['لپ تاپ مایکروسافت مدل سرفیس لپتاپ با پردازنده...'],\n",
        "#         ['کتاب اقیانوسی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'queries_embeddings' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 40\u001b[0m\n\u001b[0;32m     35\u001b[0m query_result \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39msearch for laptops\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m1\u001b[39m]),\n\u001b[0;32m     36\u001b[0m                 (\u001b[39m\"\u001b[39m\u001b[39mbest camera under 500\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m2\u001b[39m]),\n\u001b[0;32m     37\u001b[0m                 (\u001b[39m\"\u001b[39m\u001b[39mphone under 200\u001b[39m\u001b[39m\"\u001b[39m, [\u001b[39m3\u001b[39m])]\n\u001b[0;32m     38\u001b[0m clicked_rank \u001b[39m=\u001b[39m [[\u001b[39m1\u001b[39m], [\u001b[39m1\u001b[39m], [\u001b[39m1\u001b[39m]]\n\u001b[1;32m---> 40\u001b[0m graph_data \u001b[39m=\u001b[39m convert_to_graph(queries_embeddings, product_info, query_result, clicked_rank)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'queries_embeddings' is not defined"
          ]
        }
      ],
      "source": [
        "def convert_to_graph(raw_query, product_info, query_result, clicked_rank):\n",
        "    edge_index = [] # edge index\n",
        "    x = [] # node features\n",
        "    edge_attr = [] # edge features\n",
        "    query_index = {} # query index\n",
        "    product_index = {} # product index\n",
        "\n",
        "    # add query nodes\n",
        "    for idx, query in enumerate(raw_query):\n",
        "        query_index[idx] = idx\n",
        "        x.append(query)\n",
        "\n",
        "    # add product nodes\n",
        "    for idx, p in enumerate(product_info):\n",
        "        product_index[p[0]] = idx + len(raw_query)\n",
        "        x.append(p)\n",
        "\n",
        "    # add edges\n",
        "    for idx, (q, result) in enumerate(query_result):\n",
        "        for r in result:\n",
        "            edge_index.append([query_index[q], product_index[r]])\n",
        "            edge_attr.append([clicked_rank[idx][result.index(r)]])\n",
        "\n",
        "    # convert to tensor\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "    x = torch.tensor(x, dtype=torch.float)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "product_info = [[1, \"laptop\", 500, 800, 650, 5, 10, 7],\n",
        "                [2, \"camera\", 400, 450, 425, 3, 5, 4],\n",
        "                [3, \"phone\", 150, 199, 175, 2, 3, 2.5]]\n",
        "query_result = [(\"search for laptops\", [1]),\n",
        "                (\"best camera under 500\", [2]),\n",
        "                (\"phone under 200\", [3])]\n",
        "clicked_rank = [[1], [1], [1]]\n",
        "\n",
        "graph_data = convert_to_graph(queries_embeddings, product_info, query_result, clicked_rank)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import networkx as nx\n",
        "# G = nx.DiGraph() # create a directed graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To build a graph to learn to rank using PyTorch, you need to first preprocess your data to create the graph structure.\n",
        "# One approach could be to treat each query-result pair as a node in the graph, and connect the nodes that belong to the same query. The graph can then be processed with graph neural networks (GNNs) that learn to propagate information between nodes.\n",
        "\n",
        "# Here are the steps you can follow to build the graph:\n",
        "# Encode the queries and results into numerical representations: You can use pre-trained models such as BERT or other embedding methods to encode the queries and results as dense vectors.\n",
        "# Create nodes and edges in the graph: For each query-result pair, you can create a node and connect it to the other nodes that belong to the same query. You can use PyTorch's DGL library for building the graph structure.\n",
        "# Train the graph neural network: You can use a GNN model such as Graph Attention Network (GAT) to learn the representation of each node and propagate information between nodes. The final representations of nodes can then be used for ranking.\n",
        "# Evaluate the model: You can use standard evaluation metrics such as mean average precision (MAP) or normalized discounted cumulative gain (NDCG) to evaluate the performance of your model.\n",
        "# This is a high-level overview of building a graph-based learn-to-rank model. Depending on your specific requirements, you may need to make adjustments to this process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from annoy import AnnoyIndex\n",
        "\n",
        "# Create an Annoy index\n",
        "index = AnnoyIndex(queries_embeddings.shape[1])\n",
        "\n",
        "# Add the product embeddings to the index\n",
        "for i, product_embedding in enumerate(product_embeddings):\n",
        "    index.add_item(i, product_embedding)\n",
        "\n",
        "# Build the index\n",
        "index.build(10)  # 10 is the number of trees\n",
        "\n",
        "# For each query, find the nearest neighbors (products)\n",
        "for query_embedding in queries_embeddings:\n",
        "    _, neighbors = index.get_nns_by_vector(query_embedding, n=10, search_k=-1, include_distances=True)\n",
        "    # The `neighbors` list contains the indices of the nearest products to the query\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "edge_index = torch.tensor([[0, 1],\n",
        "                           [1, 0],\n",
        "                           [1, 2],\n",
        "                           [2, 1]], dtype=torch.long)\n",
        "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index.t().contiguous())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Number of nodes:\", data.x.shape[0])\n",
        "print(\"Number of edges:\", data.edge_index.shape[1])\n",
        "print(\"Node features shape:\", data.x.shape)\n",
        "print(\"Edge indices shape:\", data.edge_index.shape)\n",
        "\n",
        "node_features = data.x\n",
        "edge_indices = data.edge_index\n",
        "print(\"Node features:\", node_features)\n",
        "print(\"Edge indices:\", edge_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Degree: The number of edges connected to a node. You can compute the degree of each node by summing the number of edges for each node.\n",
        "import torch_geometric.utils as utils\n",
        "\n",
        "degree = utils.degree(data.edge_index[0], num_nodes=data.num_nodes)\n",
        "print(\"Degree of each node:\", degree)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adjacency matrix: A square matrix that shows the connections between nodes. You can compute the adjacency matrix by using the utils.to_sparse_adj function.\n",
        "\n",
        "adj = utils.to_sparse_adj(data.edge_index, num_nodes=data.num_nodes)\n",
        "print(\"Adjacency matrix:\\n\", adj)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Laplacian matrix: A matrix that captures the structure of a graph and is used in graph signal processing and graph convolutional networks. You can compute the Laplacian matrix by using the utils.normalized_cut function.\n",
        "\n",
        "laplacian = utils.normalized_cut(data.edge_index, num_nodes=data.num_nodes)\n",
        "print(\"Laplacian matrix:\\n\", laplacian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clustering coefficient: A measure of the degree to which nodes in a graph tend to cluster together. You can compute the clustering coefficient using the utils.cluster function.\n",
        "\n",
        "cc = utils.cluster(data.edge_index, num_nodes=data.num_nodes)\n",
        "print(\"Clustering coefficient of each node:\", cc)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Graph-related properties\n",
        "\n",
        "For a machine learning model for query relevance ranking, there are several graph-related features that you can explore to improve the performance of the model. Here are some of the most commonly used ones:\n",
        "\n",
        "PageRank: A measure of the importance of each node in a graph, used to rank the relevance of web pages. You can compute the PageRank of each node by using the torch_geometric.nn.models.PageRank module.\n",
        "\n",
        "HITS (Hyperlink-Induced Topic Search): A measure of the authority and hub-ness of each node in a graph, used to rank the relevance of web pages. You can compute the HITS scores of each node by using the torch_geometric.nn.models.Hits module.\n",
        "\n",
        "Betweenness centrality: A measure of the number of times a node lies on the shortest path between two other nodes, used to rank the importance of nodes in a graph. You can compute the betweenness centrality of each node by using the torch_geometric.nn.models.BetweennessCentrality module.\n",
        "\n",
        "Closeness centrality: A measure of the average distance between a node and all other nodes in a graph, used to rank the proximity of nodes in a graph. You can compute the closeness centrality of each node by using the torch_geometric.nn.models.ClosenessCentrality module.\n",
        "\n",
        "Eigenvector centrality: A measure of the influence of a node in a graph, used to rank the importance of nodes in a graph. You can compute the eigenvector centrality of each node by using the torch_geometric.nn.models.EigenvectorCentrality module.\n",
        "\n",
        "Local clustering coefficient: A measure of the number of triangles (sets of three nodes that are all connected) that are connected to a node, used to rank the importance of nodes in a graph. You can compute the local clustering coefficient of each node by using the torch_geometric.nn.models.LocalClusteringCoefficient module.\n",
        "\n",
        "Personalized PageRank: A variant of PageRank that allows for personalized rankings based on the query and user interests. You can compute the personalized PageRank of each node by using the torch_geometric.nn.models.PersonalizedPageRank module.\n",
        "\n",
        "These are just a few examples of graph-related features that you can use to improve the performance of a query relevance ranking model. There may be other features that are relevant for your specific use case, so it is important to explore and evaluate different options to see what works best for your problem.\n",
        "\n",
        "---\n",
        "\n",
        "Relevance scores: The relevance scores indicate how relevant a product is to a query. These scores can be used as the target values for the ranking model.\n",
        "Query-product pairs: The query-product pairs represent the interactions between queries and products. These pairs can be used as the input data for the ranking model.\n",
        "Features: Features can be used to represent the characteristics of the products and queries. These features can include information about the product, the query, or the interaction between the two.\n",
        "Evaluation metrics: Evaluation metrics can be used to measure the performance of the ranking model. Some commonly used metrics for ranking models include precision, recall, mean average precision (MAP), normalized discounted cumulative gain (NDCG), and area under the ROC curve (AUC).\n",
        "Hyperparameters: The ranking model may have several hyperparameters that can be tuned to improve its performance. These hyperparameters can include the learning rate, the batch size, the number of epochs, the number of hidden layers, and the number of nodes in each layer.\n",
        "Cross-validation: Cross-validation is a technique for evaluating the performance of a model by dividing the data into training and validation sets. The model is trained on the training set and evaluated on the validation set. This allows you to measure the model's performance on unseen data and prevent overfitting.\n",
        "Ensemble methods: Ensemble methods can be used to combine the predictions of multiple models to improve the performance of the ranking model. Some commonly used ensemble methods include bagging, boosting, and stacking.\n",
        "\n",
        "These are just a few examples of properties and metrics that you can explore when working with a learning to rank problem as query-product relevancy ranking. The specific properties and metrics that you should explore will depend on your specific use case and the data that you have available.\n",
        "\n",
        "Mean Average Precision (MAP): A measure of the average precision of a ranked list of documents, where precision is the number of relevant documents retrieved divided by the number of retrieved documents.\n",
        "\n",
        "Normalized Discounted Cumulative Gain (NDCG): A measure of the quality of the ranking of documents, taking into account both the relevance of the documents and their position in the ranking.\n",
        "\n",
        "Precision@K: The precision of a ranked list of documents, computed as the number of relevant documents in the top K positions divided by K.\n",
        "\n",
        "Recall@K: The recall of a ranked list of documents, computed as the number of relevant documents in the top K positions divided by the total number of relevant documents.\n",
        "\n",
        "F1-Score@K: The harmonic mean of precision and recall at position K.\n",
        "\n",
        "Mean Reciprocal Rank (MRR): The average reciprocal rank of the first relevant document in a ranked list of documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = [\"The cat is sitting on the mat.\",\n",
        "             \"A dog is barking outside.\",\n",
        "             \"The sun is shining brightly.\",\n",
        "             \"A bird is singing a beautiful song.\",\n",
        "             \"The wind is blowing gently.\",\n",
        "             \"A flower is blooming in the garden.\",\n",
        "             \"A car is driving down the street.\",\n",
        "             \"The rain is falling from the sky.\",\n",
        "             \"A tree is growing tall and strong.\",\n",
        "             \"A person is walking down the sidewalk.\",\n",
        "             \"A plane is flying overhead.\",\n",
        "             \"The ocean is vast and endless.\",\n",
        "             \"A mountain is towering above the landscape.\",\n",
        "             \"The sky is a brilliant shade of blue.\",\n",
        "             \"A river is flowing peacefully.\",\n",
        "             \"A butterfly is flitting from flower to flower.\",\n",
        "             \"The stars are twinkling in the night sky.\",\n",
        "             \"A deer is running through the forest.\",\n",
        "             \"A city is bustling with activity.\",\n",
        "             \"The moon is shining brightly.\",]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "embeddings = model.encode(sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Step 1: Embed each sentence into a fixed-length vector using a sentence embedding model\n",
        "# def get_sentence_embedding(sentence, model):\n",
        "#     sentence_embedding = model.encode([sentence])\n",
        "#     return sentence_embedding\n",
        "\n",
        "# sentences = [...]  # Your set of sentences\n",
        "num_sentences = len(sentences)\n",
        "embedding_dim = 768  # The dimension of the sentence embedding\n",
        "\n",
        "sentence_embeddings = np.zeros((num_sentences, embedding_dim))\n",
        "for i in range(num_sentences):\n",
        "    sentence_embeddings[i, :] = get_sentence_embedding(sentences[i], model)\n",
        "\n",
        "# Step 2: Compute the similarity between each pair of sentences using cosine similarity\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "similarity_matrix = np.zeros((num_sentences, num_sentences))\n",
        "for i in range(num_sentences):\n",
        "    for j in range(i + 1, num_sentences):\n",
        "        similarity_matrix[i, j] = cosine_similarity(sentence_embeddings[i, :], sentence_embeddings[j, :])\n",
        "        similarity_matrix[j, i] = similarity_matrix[i, j]\n",
        "\n",
        "# Step 3: Connect nodes that are similar to each other with edges\n",
        "threshold = 0.7 # A similarity threshold that determines whether two sentences are considered similar\n",
        "\n",
        "edge_index = []\n",
        "for i in range(num_sentences):\n",
        "    for j in range(i + 1, num_sentences):\n",
        "        if similarity_matrix[i, j] >= threshold:\n",
        "            edge_index.append([i, j])\n",
        "\n",
        "edge_index = np.array(edge_index)\n",
        "\n",
        "# Create PyTorch Geometric data object\n",
        "x = torch.tensor(sentence_embeddings, dtype=torch.float)\n",
        "data = Data(x=x, edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show values\n",
        "print(\"node values:\", data.x)\n",
        "print(\"edge indices:\", data.edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Describe the graph\n",
        "print(\"Number of nodes:\", data.x.shape[0])\n",
        "print(\"Number of edges:\", data.edge_index.shape[1])\n",
        "print(\"Node features shape:\", data.x.shape)\n",
        "print(\"Edge indices shape:\", data.edge_index.shape)\n",
        "\n",
        "# show the graph\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(range(data.x.shape[0]))\n",
        "G.add_edges_from(data.edge_index.t().numpy())\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "centrality = nx.eigenvector_centrality(G)\n",
        "print(\"Eigenvector centrality of each node:\", centrality)\n",
        "\n",
        "betweenness = nx.betweenness_centrality(G)\n",
        "print(\"Betweenness centrality of each node:\", betweenness)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "# # Step 1: Embed each sentence into a fixed-length vector using a sentence embedding model\n",
        "def get_sentence_embedding(sentence, model):\n",
        "    sentence_embedding = model.encode([sentence])\n",
        "    return sentence_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "NUM_TRAIN_SAMPLES = None\n",
        "\n",
        "def read_json_lines(path, n_lines=None):\n",
        "    \"\"\"Creates a generator which reads and returns lines of\n",
        "    a json lines file, one line at a time, each as a dictionary.\n",
        "    \n",
        "    This could be used as a memory-efficient alternative of `pandas.read_json`\n",
        "    for reading a json lines file.\n",
        "    \"\"\"\n",
        "    with open(path, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if n_lines == i:\n",
        "                break\n",
        "            yield json.loads(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = pd.DataFrame(read_json_lines('./Torob/torob-search-data_v1.jsonl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_query</th>\n",
              "      <th>result</th>\n",
              "      <th>clicked_result</th>\n",
              "      <th>clicked_rank</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>لوستر سقفی برنز</td>\n",
              "      <td>[7151290, 6462477, 7385791, 8451497, None, 269...</td>\n",
              "      <td>[9457219]</td>\n",
              "      <td>[16]</td>\n",
              "      <td>2022-07-24T09:21:58.752000+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>قیمت هلیکوپتر</td>\n",
              "      <td>[363737, 3147253, 8720128, 9796388, 1420685, 5...</td>\n",
              "      <td>[3147253, 7135387]</td>\n",
              "      <td>[1, 7]</td>\n",
              "      <td>2022-07-24T07:32:12.261000+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ساعت هوشمند</td>\n",
              "      <td>[2459592, 9391819, 4229448, 7824893, 1670767, ...</td>\n",
              "      <td>[900897, 2931230, 31302]</td>\n",
              "      <td>[7, 25, 52]</td>\n",
              "      <td>2022-07-24T02:51:35.643000+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>تفلون مایع</td>\n",
              "      <td>[5428407, 4474271, 4581189, 8504749, 4131340, ...</td>\n",
              "      <td>[7660686, 5901997, 2376830, 2383125]</td>\n",
              "      <td>[19, 18, 21, 36]</td>\n",
              "      <td>2022-07-24T02:51:54.771000+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>خط زن</td>\n",
              "      <td>[8466568, 9285461, 1105044, 1314054, 1791930, ...</td>\n",
              "      <td>[3852139]</td>\n",
              "      <td>[20]</td>\n",
              "      <td>2022-07-23T20:56:36.043000+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         raw_query                                             result  \\\n",
              "0  لوستر سقفی برنز  [7151290, 6462477, 7385791, 8451497, None, 269...   \n",
              "1    قیمت هلیکوپتر  [363737, 3147253, 8720128, 9796388, 1420685, 5...   \n",
              "2      ساعت هوشمند  [2459592, 9391819, 4229448, 7824893, 1670767, ...   \n",
              "3       تفلون مایع  [5428407, 4474271, 4581189, 8504749, 4131340, ...   \n",
              "4            خط زن  [8466568, 9285461, 1105044, 1314054, 1791930, ...   \n",
              "\n",
              "                         clicked_result      clicked_rank  \\\n",
              "0                             [9457219]              [16]   \n",
              "1                    [3147253, 7135387]            [1, 7]   \n",
              "2              [900897, 2931230, 31302]       [7, 25, 52]   \n",
              "3  [7660686, 5901997, 2376830, 2383125]  [19, 18, 21, 36]   \n",
              "4                             [3852139]              [20]   \n",
              "\n",
              "                          timestamp  \n",
              "0  2022-07-24T09:21:58.752000+00:00  \n",
              "1  2022-07-24T07:32:12.261000+00:00  \n",
              "2  2022-07-24T02:51:35.643000+00:00  \n",
              "3  2022-07-24T02:51:54.771000+00:00  \n",
              "4  2022-07-23T20:56:36.043000+00:00  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query.columns # Index(['raw_query', 'result', 'clicked_result', 'clicked_rank', 'timestamp'], dtype='object')\n",
        "\n",
        "query.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# each query is a node in the graph and each result is another node in the graph\n",
        "# each edge is a connection between a query and a result (if the result is clicked) or between two results (if they are similar)\n",
        "\n",
        "x = []\n",
        "edge_index = []\n",
        "for i, row in query.iterrows():\n",
        "    print(row)\n",
        "    x.append(get_sentence_embedding(row['raw_query'], model))\n",
        "        \n",
        "x = torch.from_numpy(np.array(x))\n",
        "\n",
        "# edge_index = np.array(edge_index)\n",
        "\n",
        "# data = Data(x=torch.tensor(x, dtype=torch.float), edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_text = torch.tensor(text_node_features, dtype=torch.float)\n",
        "x_user = torch.tensor(user_node_features, dtype=torch.float)\n",
        "data = Data(x_text=x_text, x_user=x_user, edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_sentences = len(sentences)\n",
        "embedding_dim = 768  # The dimension of the sentence embedding\n",
        "\n",
        "sentence_embeddings = np.zeros((num_sentences, embedding_dim))\n",
        "for i in range(num_sentences):\n",
        "    sentence_embeddings[i, :] = get_sentence_embedding(sentences[i], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor(sentence_embeddings, dtype=torch.float)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torob",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "feca29c23416220973296d15171f4094138037c5c00614e8735aa8f41c130470"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
