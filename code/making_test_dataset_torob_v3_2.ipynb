{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597baf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from parsivar import Normalizer\n",
    "import hazm\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99dd830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormalizer:\n",
    "    def __init__(self):\n",
    "        self.parsivar_normalizer = Normalizer(\n",
    "            statistical_space_correction=True,\n",
    "            half_space_char=\" \",\n",
    "            pinglish_conversion_needed=True,\n",
    "        )\n",
    "        self.hazm_normalizer = hazm.Normalizer(\n",
    "            remove_extra_spaces=True,\n",
    "            persian_numbers=True,\n",
    "            persian_style=True,\n",
    "            punctuation_spacing=False,\n",
    "            remove_diacritics=True,\n",
    "            affix_spacing=False,\n",
    "            token_based=True,\n",
    "        )\n",
    "\n",
    "    def normalize(self, txt):\n",
    "        return self.hazm_normalizer.normalize(\n",
    "            self.parsivar_normalizer.normalize(\n",
    "                txt.replace(\"\\n\", \" \").replace(\"\\u200c\", \" \").lower().strip()\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90b7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonFileIterator:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.f = open(path, \"r\")\n",
    "        self.i = 0\n",
    "        self.length = self.counter_lines()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        line = self.f.readline()\n",
    "        if not line:\n",
    "            # End of file\n",
    "            self.f.close()\n",
    "            raise StopIteration\n",
    "        self.i += 1\n",
    "        return json.loads(line)\n",
    "\n",
    "    def counter_lines(self):\n",
    "        with open(self.path, \"r\") as f1:\n",
    "            return sum(1 for _ in f1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c14f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_words(titles_list, index_high_len):\n",
    "    highest_len_title_words = titles_list[index_high_len].split()\n",
    "    total_new_words = []\n",
    "    for i in range(1, len(titles_list)):\n",
    "        if i != index_high_len:\n",
    "            words = titles_list[i].split()\n",
    "            new_words = [word for word in words if word not in highest_len_title_words]\n",
    "            new_words = [word for word in new_words if word not in stopwords]\n",
    "            total_new_words += new_words\n",
    "    return list(set(total_new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca533cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "normalizer = MyNormalizer()\n",
    "with open(\"stop-words.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        stopwords.append(normalizer.normalize(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info = JsonFileIterator(\"./data/products-info_v1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_lines(path, n_lines=None):\n",
    "    \"\"\"Creates a generator which reads and returns lines of\n",
    "    a json lines file, one line at a time, each as a dictionary.\n",
    "\n",
    "    This could be used as a memory-efficient alternative of `pandas.read_json`\n",
    "    for reading a json lines file.\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if n_lines == i:\n",
    "                break\n",
    "            yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09099568",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = pd.DataFrame(read_json_lines('./data/products-info_v1.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = product.set_index(\"id\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "883e7a04",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = JsonFileIterator(\"./data/test-offline-data_v1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cf69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_price(record):\n",
    "    # Check if any of the price fields are available\n",
    "    if any([record[\"min_price\"], record[\"max_price\"], record[\"avg_price\"]]):\n",
    "        # Use the minimum of the available prices\n",
    "        return min([record[\"min_price\"], record[\"max_price\"], record[\"avg_price\"]])\n",
    "    # If no price is available, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c80b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f0767a882a432181dfeb90a26568df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"test_dataset_torob_v3_2.txt\", \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "\n",
    "    #######################################\n",
    "    # with open(\"test_dataset_v4.txt\", \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    #######################################\n",
    "\n",
    "    wrtiter = csv.writer(csvfile)\n",
    "    wrtiter.writerow(\n",
    "        [\n",
    "            \"row_number\",\n",
    "            \"query\",\n",
    "            \"product_id\",\n",
    "            \"p_des\",\n",
    "            \"category_name\",\n",
    "            \"min_num_shops\",\n",
    "            \"max_num_shops\",\n",
    "            \"avg_num_shops\",\n",
    "            \"min_price\",\n",
    "            \"max_price\",\n",
    "            \"avg_price\",\n",
    "            \"mean_min_prices\",\n",
    "            \"mean_max_prices\",\n",
    "            \"mean_avg_prices\",\n",
    "            \"std_min_prices\",\n",
    "            \"std_max_prices\",\n",
    "            \"std_avg_prices\",\n",
    "            \"price_level\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    #######################################\n",
    "    # conn = sqlite3.connect(\"my_database.db\")\n",
    "    # c = conn.cursor()\n",
    "    #######################################\n",
    "\n",
    "    data_list = []\n",
    "    for idx, test_rec in enumerate(tqdm_notebook(test_data)):\n",
    "        query = test_rec[\"raw_query\"]\n",
    "        results = test_rec[\"result_not_ranked\"]\n",
    "        min_prices = []\n",
    "        max_prices = []\n",
    "        avg_prices = []\n",
    "\n",
    "        for product_id in results:\n",
    "            if product_id != None:\n",
    "                result_product = product.loc[product_id]\n",
    "\n",
    "                #######################################\n",
    "                # c.execute(\"SELECT * FROM products WHERE id = ?\", (product_id,))\n",
    "                # result_product = c.fetchone()\n",
    "                #######################################\n",
    "\n",
    "                if result_product[2] != None:\n",
    "                    if result_product[2] != None:\n",
    "                        min_prices.append(result_product[2])\n",
    "                    if result_product[3] != None:\n",
    "                        max_prices.append(result_product[3])\n",
    "                    if result_product[4] != None:\n",
    "                        avg_prices.append(result_product[4])\n",
    "\n",
    "            mean_min_prices = np.mean(min_prices)\n",
    "            mean_max_prices = np.mean(max_prices)\n",
    "            mean_avg_prices = np.mean(avg_prices)\n",
    "\n",
    "            std_min_prices = np.std(min_prices)\n",
    "            std_max_prices = np.std(max_prices)\n",
    "            std_avg_prices = np.std(avg_prices)\n",
    "\n",
    "        for product_id in results:\n",
    "            if product_id != None:\n",
    "                result_product = product.loc[product_id]\n",
    "\n",
    "                #######################################\n",
    "                # c.execute(\"SELECT * FROM products WHERE id = ?\", (product_id,))\n",
    "                # result_product = c.fetchone()\n",
    "                #######################################\n",
    "\n",
    "                category_name = result_product[0]\n",
    "                min_price = result_product[2]\n",
    "                max_price = result_product[3]\n",
    "                avg_price = result_product[4]\n",
    "\n",
    "                #######################################\n",
    "                # titles_list_product = json.loads(result_product[2])\n",
    "                #######################################\n",
    "\n",
    "                titles_list_product = product.loc[product_id][\"titles\"]\n",
    "\n",
    "                if len(titles_list_product) > 0:\n",
    "                    min_num_shops = result_product[5]\n",
    "                    max_num_shops = result_product[6]\n",
    "                    avg_num_shops = result_product[7]\n",
    "\n",
    "                    highest_len_product = max(titles_list_product, key=len)\n",
    "                    index_highest_len_product = titles_list_product.index(\n",
    "                        highest_len_product\n",
    "                    )\n",
    "                    product_title_new_words = find_new_words(\n",
    "                        titles_list_product, index_highest_len_product\n",
    "                    )\n",
    "                    p_des = \" \".join(\n",
    "                        [highest_len_product, \" \".join(product_title_new_words)]\n",
    "                    ).replace(\"\\u200c\", \" \")\n",
    "                    \n",
    "                    # Get the minimum price\n",
    "                    # print(product.loc[product_id])\n",
    "                    minimum_price = get_min_price(product.loc[product_id])\n",
    "                    \n",
    "                    if minimum_price is not None and minimum_price > 0:\n",
    "                        price_level = int(np.log2(int(minimum_price) + 1))\n",
    "                    else:\n",
    "                        price_level = int(np.log2(0 + 1))\n",
    "\n",
    "                    # Format the result\n",
    "                    # price_level = f\"price level is {price}\"\n",
    "\n",
    "                    wrtiter.writerow(\n",
    "                        [\n",
    "                            idx,\n",
    "                            normalizer.normalize(query),\n",
    "                            product_id,\n",
    "                            p_des,\n",
    "                            category_name,\n",
    "                            min_num_shops,\n",
    "                            max_num_shops,\n",
    "                            avg_num_shops,\n",
    "                            min_price,\n",
    "                            max_price,\n",
    "                            avg_price,\n",
    "                            mean_min_prices,\n",
    "                            mean_max_prices,\n",
    "                            mean_avg_prices,\n",
    "                            std_min_prices,\n",
    "                            std_max_prices,\n",
    "                            std_avg_prices,\n",
    "                            price_level,\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_dataset_torob_v3_2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cabc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f662b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://kkb-production.jupyter-proxy.kaggle.net/k/121749410/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..29XB1I5T3_TLKwAe_WqY7Q.ZYbku6W-CUIjUa4EdNr59IoVeaAG1K5-G3q4YcfDzWz_s9E5ys6pXOnxSAiWKMpS4v6RO-UvQWT-KHlTsFqgTbSZU9lKSogRXgVjzVOvksfyk55_zeK6pizUv0hh6rxUooYHlPsymAqz2R4BRVm9jMqHZd_4Tm4ien3sQ73MQFDWiOY_xoV69R-LZNnlfqplstml3Cy9VkZfWRAbag9A6w.Mbb_mG6vQ0U4maSp3wdGOQ/proxy/files/torobv3_bert_epoch-3_1st.w\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!rsync -rhPu --info=progress2 \"/content/torobv3_bert_epoch-3_1st.w\" \"/content/drive/MyDrive/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
